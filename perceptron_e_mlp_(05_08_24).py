# -*- coding: utf-8 -*-
"""Perceptron e MLP (05/08/24).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14plhPDeSb8drKwcqw8FQVF-6dkwiPNpx

**Importando bibliotecas**
"""

import pandas as pd
import sklearn as sk
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import Perceptron
from sklearn.neural_network import MLPClassifier

"""**Carregando conjunto de dados**"""

dados = pd.read_csv("ObesityDataSet_Alterada.csv")
dados = shuffle(dados)
X = dados.iloc[:,:-1]
Y = dados.iloc[:,-1]

"""**Gerando os conjuntos de treino, teste e validação**

"""

x_treino,x_temp,y_treino,y_temp=train_test_split(X,Y,test_size=0.5,stratify=Y)
x_validacao,x_teste,y_validacao,y_teste=train_test_split(x_temp,y_temp,test_size=0.5, stratify = y_temp)

print("Treino")
x_treino.info()
y_treino.info()

print("\nValidação")
x_validacao.info()
y_validacao.info()

print("\nTeste")
x_teste.info()
y_teste.info()

"""

Começando a usar uma Árvore de Decisão
**negrito**"""

#sem setar valores aos hiperparâmetros
Pe = Perceptron()
Pe.fit(x_treino,y_treino)
opiniao = Pe.predict(x_teste)
print("Acurácia com parâmetros default: ",accuracy_score(y_teste, opiniao))

#atribuindo valores aos hiperparâmetros
#n_neighbors corresponde ao tamanho da vizinhança
#weights indica se os vizinhos terão pesos diferentes ou não. Pode assumir os valores uniform ou distante (ou callabe)

Pe = Perceptron(max_iter=1000,eta0=0.9,early_stopping=True)
Pe.fit(x_treino,y_treino)
opiniao = Pe.predict(x_teste)
print("Acurácia com parâmetros default: ",accuracy_score(y_teste, opiniao))

#testando todos as possibilidades em um conjunto finito de possibilidades de parâmetros
maior = -1
for i in range (100,1500,100):  #max_iter
  for e in (0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0):  #eta0
    for es in (True,False):
      Pe = Perceptron(max_iter=i,eta0=e,early_stopping=es)
      Pe.fit(x_treino,y_treino)
      opiniao = Pe.predict(x_validacao)
      Acc = accuracy_score(y_validacao, opiniao)
      #print("max_iter ",i," eta0: ",e," early_stopping: ",es)
      if (Acc > maior):
        maior = Acc
        mi = i
        eta = e
        early = es

print("\nMelhor configuração para o SVM")
print("max_iter ",mi," eta0: ",eta," early_stopping: ",early)

print("\n\nDesempenho sobre o conjunto de teste")
Pe = Perceptron(max_iter=mi,eta0=eta,early_stopping=early)
Pe.fit(x_treino,y_treino)
opiniao = Pe.predict(x_teste)
print("Acurácia sobre o teste: ",accuracy_score(y_teste, opiniao))

maior = -1
for i in (5,6,10,12):
   for j in ('constant','invscaling', 'adaptive'):
      for k in (50,100,150,300,500,1000):
        for l in ('identity', 'logistic', 'tanh', 'relu'):
            MLP = MLPClassifier(hidden_layer_sizes=(i,i,i), learning_rate=j, max_iter=k, activation=l )
            MLP.fit(x_treino,y_treino)

            opiniao = MLP.predict(x_validacao)
            Acc = accuracy_score(y_validacao, opiniao)
            print("Acurácia: ",Acc)

            if (Acc > maior):
              maior = Acc
              Melhor_i = i
              Melhor_j = j
              Melhor_k = k
              Melhor_l = l

print("Acc do  MLP sobre o conjunto de teste")
MLP = MLPClassifier(hidden_layer_sizes=(Melhor_i,Melhor_i,Melhor_i), learning_rate=Melhor_j, max_iter=Melhor_k, activation=Melhor_l)
MLP.fit(x_treino,y_treino)
opiniao = MLP.predict(x_teste)
Acc = accuracy_score(y_teste, opiniao)
print(Acc)