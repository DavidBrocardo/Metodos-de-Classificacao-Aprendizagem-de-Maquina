# -*- coding: utf-8 -*-
"""KNN (08/07/24).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pO5rW3xUPL7R1YAMlq26Iorzg1HD4VXl
"""

import pandas as pd
import sklearn as sk
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier

"""
**Analisando Conjunto de Dados**

Base de Dados: vertebral

https://archive.ics.uci.edu/dataset/212/vertebral+column

Composta de 310 instâncias

2 Classes:

AB (210 casos)  --> classe 1

NO (100 casos)  --> classe 2


6 atributos:

pelvic_incidence (float)

pelvic_tilt (float)

lumbar_lordosis_angle (float)

sacral_slope (float)

pelvic_radius (float)

degree_spondylolisthesis (float)

class



"""

dados = pd.read_csv("ObesityDataSet_Alterada.csv")
print(dados.head())
print("\n\n\n")
print(dados.info())

dados = shuffle(dados)
print("\n\n\n")
print(dados.head())

X = dados.iloc[:,:-1]
Y = dados.iloc[:,-1]

"""**Gerando os conjuntos de treino, teste e validação**

"""

x_treino,x_temp,y_treino,y_temp=train_test_split(X,Y,test_size=0.5,stratify=Y)
x_validacao,x_teste,y_validacao,y_teste=train_test_split(x_temp,y_temp,test_size=0.5, stratify = y_temp)

print("Treino")
x_treino.info()
y_treino.info()

print("\nValidação")
x_validacao.info()
y_validacao.info()

print("\nTeste")
x_teste.info()
y_teste.info()

"""

Começando a usar o KNN
"""

#sem setar valores aos hiperparâmetros
KNN = KNeighborsClassifier()
KNN.fit(x_treino,y_treino)
opiniao = KNN.predict(x_teste)
print("Acurácia com parâmetros default: ",accuracy_score(y_teste, opiniao))

#atribuindo valores aos hiperparâmetros
#n_neighbors corresponde ao tamanho da vizinhança
#weights indica se os vizinhos terão pesos diferentes ou não. Pode assumir os valores uniform ou distante (ou callabe)

KNN = KNeighborsClassifier(n_neighbors=7,weights="uniform")
KNN.fit(x_treino,y_treino)
opiniao = KNN.predict(x_teste)
print("Acurácia com parâmetros default: ",accuracy_score(y_teste, opiniao))

#encontrando o melhor K através da regra do cotovelo
#encontra-se o melhor K sobre o conjunto de validação
taxa_de_erro = []
for i in range (1,50):
  KNN = KNeighborsClassifier(n_neighbors=i,weights="distance")
  KNN.fit(x_treino,y_treino)
  opiniao = KNN.predict(x_validacao)
  taxa_de_erro.append(np.mean(opiniao!=y_validacao))
  #print("K: ",i," Acc: ",accuracy_score(y_validacao, opiniao))

print("\n\nVetor de Erros")
print(taxa_de_erro)


melhor_k=np.argmin(taxa_de_erro)+1
print("\nMelhor K:", melhor_k,"\n\n")

plt.figure (figsize=(11,7))
plt.plot(range(1,50),taxa_de_erro,color='blue',linestyle='dashed',marker='o')
plt.xlabel('K')
plt.ylabel('Erro')
plt.show()

#aplica-se o K encontrado em um KNN sobre o conjunto de teste
KNN = KNeighborsClassifier(n_neighbors=melhor_k,weights="distance")
KNN.fit(x_treino,y_treino)
opiniao = KNN.predict(x_teste)
print("\n\nK: ",i," Acurácia sobre o teste: ",accuracy_score(y_teste, opiniao))

#testando todos as possibilidades em um conjunto finito de possibilidades de parâmetros
maior = -1
for j in ("distance","uniform"):
  for i in range (1,50):
    KNN = KNeighborsClassifier(n_neighbors=i,weights=j)
    KNN.fit(x_treino,y_treino)
    opiniao = KNN.predict(x_validacao)
    Acc = accuracy_score(y_validacao, opiniao)
    print("K: ",i," Métrica: ",j," Acc: ",Acc)
    if (Acc > maior):
      maior = Acc
      Melhor_k = i
      Melhor_metrica = j

print("\nMelhor configuração para o KNN")
print("K: ",Melhor_k," Métrica: ",Melhor_metrica," Acurácia sobre a validação: ",maior)

print("\n\nDesempenho sobre o conjunto de teste")
KNN = KNeighborsClassifier(n_neighbors=i,weights=j)
KNN.fit(x_treino,y_treino)
opiniao = KNN.predict(x_teste)
print("\n\nK: ",i," Acurácia sobre o teste: ",accuracy_score(y_teste, opiniao))