# -*- coding: utf-8 -*-
"""AD (08/07/24).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sZx1olXiQUA-_aHfepcvMkicE9Yd8vHV

**Importando bibliotecas**
"""

import pandas as pd
import sklearn as sk
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

"""**Carregando conjunto de dados**"""

dados = pd.read_csv("ObesityDataSet_Alterada.csv")
dados = shuffle(dados)
X = dados.iloc[:,:-1]
Y = dados.iloc[:,-1]

"""**Gerando os conjuntos de treino, teste e validação**

"""

x_treino,x_temp,y_treino,y_temp=train_test_split(X,Y,test_size=0.5,stratify=Y)
x_validacao,x_teste,y_validacao,y_teste=train_test_split(x_temp,y_temp,test_size=0.5, stratify = y_temp)

print("Treino")
x_treino.info()
y_treino.info()

print("\nValidação")
x_validacao.info()
y_validacao.info()

print("\nTeste")
x_teste.info()
y_teste.info()

"""

Começando a usar uma Árvore de Decisão
**negrito**"""

#sem setar valores aos hiperparâmetros
AD = DecisionTreeClassifier()
AD.fit(x_treino,y_treino)
opiniao = AD.predict(x_teste)
print("Acurácia com parâmetros default: ",accuracy_score(y_teste, opiniao))

#atribuindo valores aos hiperparâmetros
#n_neighbors corresponde ao tamanho da vizinhança
#weights indica se os vizinhos terão pesos diferentes ou não. Pode assumir os valores uniform ou distante (ou callabe)

AD = DecisionTreeClassifier(criterion='entropy',max_depth=7,min_samples_leaf=3,min_samples_split=5,splitter='best')
AD.fit(x_treino,y_treino)
opiniao = AD.predict(x_teste)
print("Acurácia com parâmetros default: ",accuracy_score(y_teste, opiniao))

#testando todos as possibilidades em um conjunto finito de possibilidades de parâmetros
maior = -1
for j in ("entropy","gini"):  #criterion
  for i in range (1,11):      #max_depth
    for k in range (1,11):    #min_samples_leaf
      for l in range (2,16):  #min_samples_split
        for m in ('best','random'): #splitter
          AD = DecisionTreeClassifier(criterion=j,max_depth=i,min_samples_leaf=k,min_samples_split=l,splitter=m)
          AD.fit(x_treino,y_treino)
          opiniao = AD.predict(x_validacao)
          Acc = accuracy_score(y_validacao, opiniao)
          #print("Criterion: ",j," max_depth: ",i," min_samples_leaf: ",k," min_samples_split: ",l," splitter: ",m," Acc: ",Acc)
          if (Acc > maior):
            maior = Acc
            crit = j
            md = i
            msl = k
            mss = l
            split = m

print("\nMelhor configuração para a AD")
print("Criterion: ",crit," max_depth: ",md," min_samples_leaf: ",msl," min_samples_split: ",mss," splitter: ",split," Acc: ",maior)

print("\n\nDesempenho sobre o conjunto de teste")
AD = DecisionTreeClassifier(criterion=crit,max_depth=md,min_samples_leaf=msl,min_samples_split=mss,splitter=split)
AD.fit(x_treino,y_treino)
opiniao = AD.predict(x_teste)
print("Acurácia sobre o teste: ",accuracy_score(y_teste, opiniao))